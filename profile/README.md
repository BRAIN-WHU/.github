
<h2 align="center"> <p> 🎓 🎯 BRAIN-WHU 🔔 📒 </p></h2>

We are a research team from the BRAIN Laboratory (Beidou Robots And Intelligent Navigation laboratory) of Wuhan University. For positioning and navigation tasks, we mainly study machine learning and positioning and navigation algorithms. For example, GNSS/INS integrated navigation, visual/LIDAR SLAM under deep learning, deep learning multi-modal data fusion, panoramic navigation perception, etc. Check our works by topic:

<details>
  <summary><strong>About BRAIN Lab</strong> (click to expand):</summary>
  
  - Lab Leader
    - [Chi Guo (郭迟)](http://jszy.whu.edu.cn/guochi/zh_CN/index.htm): Professor at Wuhan University Satellite Navigation and Positioning Technology Research Center, Wuhan University Luojia Laboratory, Wuhan University Artificial Intelligence Research Institute, leader of BRAIN LAB.
  - Activate Members
    - [Wenfei Guo (郭文飞)](http://jszy.whu.edu.cn/guowenfei/zh_CN/index/414863/list/index.htm): Professor at Wuhan University Satellite Navigation and Positioning Technology Research Center. Research high-precision positioning and timing
    - [Jingsong Cui (崔竞松)](http://jszy.whu.edu.cn/cuijingsong/zh_CN/index/216789/list/index.htm): Associate professor at the School of Cyberspace Security of Wuhan University, researching network security based on Beidou high-precision timing technology.
    - [Rong Peng (彭蓉)](https://cs.whu.edu.cn/info/1019/2951.htm): Professor, School of Computer Science, Wuhan University.
    - [Yarong Luo (罗亚荣)](): Postdoctoral fellow at Wuhan University Satellite Navigation and Positioning Technology Research Center.
</details>

<details>
  <summary><strong>Integration of deep learning and SLAM</strong> (click to expand):</summary>

  - 📂 [SuperVINS](https://github.com/luohongk/SuperVINS) ![Github stars](https://img.shields.io/github/stars/luohongk/SuperVINS.svg) : A visual-inertial SLAM framework integrated deep learning features;
</details>

<!-- <details>
  <summary><strong>Public datasets</strong> (click to expand):</summary>
  
  - 📂 [WHU-TLS](https://github.com/WHU-USI3DV/WHU-TLS) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/WHU-TLS.svg) : TLS PC registration benchmark covering 11 scenarios;
  - 📂 [WHU-Helmet](https://github.com/kafeiyin00/WHU-HelmetDataset) ![Github stars](https://img.shields.io/github/stars/kafeiyin00/WHU-HelmetDataset.svg) : A helmet-based multi-sensor SLAM benchmark;
  - 📂 [WHU-Urban-3D](https://whu3d.com/) : ALS/MLS semantic/instance segmentation benchmark;
  - 📂 [WHU-Railway3D](https://github.com/WHU-USI3DV/WHU-Railway3D) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/WHU-Railway3D.svg) : Semantic segmentation benchmark for railway scenario;
</details> -->

<!-- <details>
  <summary><strong>Point Cloud Registration</strong> (click to expand):</summary>
  
  - 📂 [BSC (ISPRS J'17)](https://github.com/YuePanEdward/GH-ICP/blob/master/include/binary_feature_extraction.hpp) ![Github stars](https://img.shields.io/github/stars/YuePanEdward/GH-ICP.svg) : A handcrafted point cloud local descriptor utilizing CPU;
  - 📂 [YOHO (ACM MM'22)](https://github.com/HpWang-whu/YOHO) ![Github stars](https://img.shields.io/github/stars/HpWang-whu/YOHO.svg) : A learning-based point cloud local rotation-equivariant descriptor;
  - 📂 [RoReg (TPAMI'23)](https://github.com/HpWang-whu/RoReg) ![Github stars](https://img.shields.io/github/stars/HpWang-whu/RoReg.svg) : Utilizing rotation-equivariance in the whole pipeline of pairwise registration;
  - 📂 [SGHR (CVPR'23)](https://github.com/WHU-USI3DV/SGHR) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/SGHR.svg) : A simple multiview pc registration baseline;
  - 📂 [MSReg (IEEE TGRS'24)](https://github.com/WHU-USI3DV/MSReg) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/MSReg.svg) : Fast 4DOF registration of MLS and stereo point clouds;
</details> -->

<!-- <details>
  <summary><strong>Image-to-point cloud Registration</strong> (click to expand):</summary>
  
  - 📂 [FreeReg (ICLR'24)](https://github.com/WHU-USI3DV/FreeReg) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/FreeReg.svg) : FreeReg extracts cross-modality features from pretrained diffusion models and monocular depth estimators for accurate zero-shot image-to-point cloud registration;
  - 📂 [CoFiI2P (Arxiv'23)](https://github.com/WHU-USI3DV/CoFiI2P) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/CoFiI2P.svg) : CoFiI2P is a coarse-to-fine framework for image-to-point cloud registration task;
</details> -->

<!-- <details>
  <summary><strong>Point Cloud Upsampling</strong> (click to expand):</summary>
  
  - 📂 [PC2-PU (ACM MM'22)](https://github.com/chenlongwhu/PC2-PU) ![Github stars](https://img.shields.io/github/stars/chenlongwhu/PC2-PU.svg) : A transformer-based point cloud upsampling baseline;
</details> -->

<!-- <details>
  <summary><strong>Point Cloud / Depth Completion</strong> (click to expand):</summary>
  
  - 📂 [KT-Net (AAAI'23)](https://github.com/a4152684/KT-Net) ![Github stars](https://img.shields.io/github/stars/a4152684/KT-Net.svg) : A transformer-based point cloud completion baseline;
  - 📂 [SparseDC (Information Fusion'24)](https://github.com/WHU-USI3DV/SparseDC) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/SparseDC.svg) : Depth Completion from sparse and non-uniform inputs;
  - 📂 [EGIInet (ECCV'24)](https://github.com/WHU-USI3DV/EGIInet) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/EGIInet.svg) : Single view image guided point cloud completion framework;
</details> -->

<!-- <details>
  <summary><strong>Point Cloud Localization</strong> (click to expand):</summary>
  
  - 📂 [PatchAugNet (ISPRS J'23)](https://github.com/WHU-USI3DV/PatchAugNet) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/PatchAugNet.svg) : A cross-platform pc localization baseline;
  - 📂 [LAWS (ISPRS J'24)](https://github.com/WHU-USI3DV/LAWS) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/LAWS.svg) : Regard point cloud localization as a classification problem;
</details> -->

<!-- <details>
  <summary><strong>Normal Estimation</strong> (click to expand):</summary>
  
  - 📂 [AdaFit (ICCV'21)](https://github.com/Runsong123/AdaFit) ![Github stars](https://img.shields.io/github/stars/Runsong123/AdaFit.svg) : Rethinking pc normal estimation;
</details> -->

<!-- <details>
  <summary><strong>Object Detection</strong> (click to expand):</summary>
  
  - 📂 [ME-Net (JAG'23)](https://github.com/WHU-USI3DV/MENet) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/MENet.svg) : Objection detection utilizing both image and Lidar from mobile platform;
</details> -->

<!-- <details>
  <summary><strong>Image / Point Cloud Semantic Segmentation</strong> (click to expand):</summary>
  
  - 📂 [Mobile-Seed (RAL'24)](https://github.com/WHU-USI3DV/Mobile-Seed) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/Mobile-Seed.svg) : An online framework for simultaneous semantic segmentation and boundary detection on compact robots;
</details> -->

<!-- <details>
  <summary><strong> Urban Morphology & Sustainable Development </strong> (click to expand):</summary>
  
  - 📂 [3DBIE-SolarPV (Applied Energy‘24)](https://github.com/WHU-USI3DV/3DBIE-SolarPV) ![Github stars](https://img.shields.io/github/stars/WHU-USI3DV/3DBIE-SolarPV.svg) : City-scale solar PV potential estimation on 3D buildings using multi-source RS data: A case study in Wuhan, China;
</details> -->




